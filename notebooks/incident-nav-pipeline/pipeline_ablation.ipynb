{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Incident Navigator pipeline\n",
    "\n",
    "In this notebook we build and evalate out our pipeline\n",
    "\n",
    "![Image](pipeline.png)\n",
    "\n",
    "Note that certain cell outputs were erased as unfortunately due to rate limiters associate with GroqCloud we have had to run this notebook multiple times over the course of the project and note all cells were run every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import weaviate\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from weaviate.classes.query import Filter\n",
    "from pymongo import MongoClient\n",
    "from langchain.retrievers.document_compressors.base import BaseDocumentCompressor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from flashrank import Ranker, RerankRequest\n",
    "from typing import Optional\n",
    "import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "weaviate_client = weaviate.connect_to_local(port=8081)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\", cache_folder=\"./embedding_model\")\n",
    "MONGO_URI = \"mongodb://root:root@localhost:27017/\"\n",
    "DATABASE_NAME = \"incident_db\"\n",
    "COLLECTION_NAME = \"incident_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import root_validator\n",
    "\n",
    "class CustomReranker(BaseDocumentCompressor):\n",
    "    \"\"\"Document compressor using Flashrank interface.\"\"\"\n",
    "\n",
    "    client: Ranker\n",
    "    \"\"\"Flashrank client to use for compressing documents\"\"\"\n",
    "    top_n: int = 3\n",
    "    \"\"\"Number of documents to return.\"\"\"\n",
    "    model: Optional[str] = None\n",
    "    \"\"\"Model to use for reranking.\"\"\"\n",
    "\n",
    "    class Config:\n",
    "        extra = 'forbid'\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_environment(cls, values):\n",
    "        \"\"\"Validate that api key and python package exists in environment.\"\"\"\n",
    "        try:\n",
    "            from flashrank import Ranker\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import flashrank python package. \"\n",
    "                \"Please install it with `pip install flashrank`.\"\n",
    "            )\n",
    "\n",
    "        values[\"model\"] = values.get(\"model\", \"ms-marco-MiniLM-L-12-v2\")\n",
    "        values[\"client\"] = Ranker(model_name=values[\"model\"], cache_dir=\"reranker\")\n",
    "        return values\n",
    "\n",
    "    def compress_documents(\n",
    "        self,\n",
    "        documents,\n",
    "        query,\n",
    "        callbacks = None):\n",
    "        passages = [\n",
    "            {\"id\": i, \"text\": doc.page_content, \"metadata\": doc.metadata} for i, doc in enumerate(documents)\n",
    "        ]\n",
    "        rerank_request = RerankRequest(query=query, passages=passages)\n",
    "        rerank_response = self.client.rerank(rerank_request)[:self.top_n]\n",
    "        final_results = []\n",
    "        for r in rerank_response:\n",
    "            doc = Document(\n",
    "                page_content=r[\"text\"],\n",
    "                metadata={\n",
    "                    **r['metadata'],\n",
    "                    \"id\": r[\"id\"],\n",
    "                    \"relevance_score\": r[\"score\"]\n",
    "                },\n",
    "            )\n",
    "            final_results.append(doc)\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flashrank.Ranker:Downloading ms-marco-MiniLM-L-12-v2...\n",
      "ms-marco-MiniLM-L-12-v2.zip: 100%|██████████| 21.6M/21.6M [00:01<00:00, 16.2MiB/s]\n"
     ]
    }
   ],
   "source": [
    "compressor = CustomReranker()\n",
    "\n",
    "def create_retriever(industries):\n",
    "    filters = None\n",
    "    if not industries == 'all':\n",
    "        filters = Filter.any_of([Filter.by_property(\"industry\").equal(industry) for industry in industries])\n",
    "    db = WeaviateVectorStore(client=weaviate_client, index_name=\"incident\", text_key=\"text\", embedding=embeddings)\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor = compressor,\n",
    "        base_retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"fetch_k\": 20, 'filters': filters})\n",
    "    )\n",
    "    return compression_retriever\n",
    "\n",
    "def get_documents_ids(retrieved_docs):\n",
    "    if retrieved_docs:\n",
    "        return [int(doc.metadata['incident_id']) for doc in retrieved_docs]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_documents_by_ids(ids):\n",
    "    try:\n",
    "        client = MongoClient(MONGO_URI)\n",
    "        db = client[DATABASE_NAME]\n",
    "        collection = db[COLLECTION_NAME]        \n",
    "        documents = list(collection.find({\"accident_id\": {\"$in\": ids}}))\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        return []\n",
    "    finally:\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  openai_api_base=\"https://api.groq.com/openai/v1/\",\n",
    "  model = \"llama3-8b-8192\",\n",
    "  temperature=0.7,\n",
    "  api_key=\"\"\n",
    ")\n",
    "\n",
    "CONTEXT_TEMPLATE = \"\"\"\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "Given a discussion history and a follow-up question, rewrite the follow-up question to be fully self-contained and understandable without the context of the previous conversation. Keep it as close as possible to the original meaning but include any relevant details from the history if they add clarity or context. If no additional context is needed, leave the question unchanged.\n",
    "Discussion history:{chat_history}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CONTEXT_PROMPT = ChatPromptTemplate.from_template(CONTEXT_TEMPLATE)\n",
    "\n",
    "SYSTEM_TEMPLATE = \"\"\"\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are IncidentNavigator, an AI designed to assist in managing and understanding incidents using a dataset of incident records. Your role is to provide precise, concise, and clear responses based on the context of the documents you receive. If a question falls outside of the information available in the provided context, you should clearly state that you cannot provide an answer but will offer the best response based on what is available.\n",
    "The documents you process include the following fields:\n",
    "- accident_id: Unique identifier for each incident.\n",
    "- event_type: Category of the incident (e.g., fire, collision).\n",
    "- industry_type: The sector or industry where the incident occurred (e.g., construction, transportation).\n",
    "- accident_title: A brief, descriptive title for the accident.\n",
    "- start_date: The date and time the incident began.\n",
    "- finish_date: The date and time the incident ended or was resolved.\n",
    "- accident_description: A detailed account of how the accident occurred.\n",
    "- causes_of_accident: Factors or conditions leading to the incident.\n",
    "- consequences: Outcomes or impacts of the incident (e.g., injuries, damage).\n",
    "- emergency_response: Immediate actions taken to manage the incident.\n",
    "- lesson_learned: Insights or recommendations for future prevention.\n",
    "- url: Reference link to the document webpage.\n",
    "When answering questions, follow these guidelines:\n",
    "- Context Provided: If the context includes information related to these fields, provide a direct and detailed response based on the relevant data.\n",
    "- Context Missing or Insufficient: If no context or relevant information is provided:\n",
    "  - State that you cannot provide a definitive answer because the requester does not have sufficient privileges or the information is unavailable.\n",
    "  - Do not speculate but offer a general response or guidance based on the type of question, when possible.\n",
    "Context: {context}\n",
    "IMPORTANT: KEEP YOUR ANSWERS AS CONCISE AND RELEVANT AS POSSIBLE, DON'T GIVE OUT UNNECESSARALY LONG ANSWERS.\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = ChatPromptTemplate.from_template(SYSTEM_TEMPLATE)\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "  def default(self, obj):\n",
    "      if isinstance(obj, datetime):\n",
    "          return obj.isoformat()\n",
    "      return super().default(obj)\n",
    "  \n",
    "def retrieve(data):\n",
    "  query = data['question']\n",
    "  retriever = create_retriever('all')\n",
    "  docs = retriever.invoke(query)\n",
    "  ids = get_documents_ids(docs)\n",
    "  retrieved_docs = get_documents_by_ids(ids)\n",
    "  for document in retrieved_docs:\n",
    "      document.pop(\"_id\", None)\n",
    "  data['context'] = retrieved_docs\n",
    "  return data\n",
    "\n",
    "def get_industry(placeholder = None):\n",
    "  return ['processing of metals', 'power generation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How should I respond to a fire in an industria...</td>\n",
       "      <td>Immediately activate fire alarm, evacuate non-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are signs of an imminent explosion risk i...</td>\n",
       "      <td>Abnormal pressure readings, unusual temperatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm seeing sludge overflow in my refinery's bi...</td>\n",
       "      <td>Likely filamentous bacteria growth caused by: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What immediate actions should be taken if toxi...</td>\n",
       "      <td>Activate emergency alarms, evacuate personnel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I safely handle a chemical spill in a p...</td>\n",
       "      <td>Identify spilled substance from safety data sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What safety measures are essential for oxygen ...</td>\n",
       "      <td>Regular inspection of trapping sieves, tempera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How should I respond to a pressure vessel show...</td>\n",
       "      <td>Evacuate area immediately, activate emergency ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are warning signs of a runaway chemical r...</td>\n",
       "      <td>Unexpected temperature increase, unusual color...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What precautions are needed when handling sodi...</td>\n",
       "      <td>Keep away from moisture and heat above 40°C, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I respond to a leak in a gas storage fa...</td>\n",
       "      <td>Activate emergency shutdown systems, evacuate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What should I do if electrical equipment catch...</td>\n",
       "      <td>Cut power supply if safe, use appropriate fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How do I safely manage batch reactor temperatu...</td>\n",
       "      <td>Monitor temperature continuously, maintain coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What are key considerations for storing flamma...</td>\n",
       "      <td>Proper ventilation, temperature control, segre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How should I respond to a cooling system failu...</td>\n",
       "      <td>Initiate emergency shutdown procedures, activa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What measures prevent dust explosions in proce...</td>\n",
       "      <td>Regular cleaning schedule, proper ventilation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How do I handle a leak in pressurized equipment?</td>\n",
       "      <td>Isolate affected equipment, evacuate area, wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What safety checks are needed before maintenan...</td>\n",
       "      <td>Verify lockout/tagout, test for hazardous atmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How should I respond to a chemical exposure in...</td>\n",
       "      <td>Remove affected person from exposure, use emer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are signs of imminent equipment failure?</td>\n",
       "      <td>Unusual noise or vibration, unexpected tempera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How do I safely conduct hot work in hazardous ...</td>\n",
       "      <td>Obtain hot work permit, check for flammable at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What emergency procedures are needed for power...</td>\n",
       "      <td>Activate emergency power systems, secure criti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How should I handle a toxic material release?</td>\n",
       "      <td>Activate emergency response plan, evacuate aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What are proper procedures for chemical waste ...</td>\n",
       "      <td>Identify waste type, use proper containers, en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How do I respond to an automatic fire suppress...</td>\n",
       "      <td>Establish fire watch, notify maintenance, veri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Input  \\\n",
       "0   How should I respond to a fire in an industria...   \n",
       "1   What are signs of an imminent explosion risk i...   \n",
       "2   I'm seeing sludge overflow in my refinery's bi...   \n",
       "3   What immediate actions should be taken if toxi...   \n",
       "4   How do I safely handle a chemical spill in a p...   \n",
       "5   What safety measures are essential for oxygen ...   \n",
       "6   How should I respond to a pressure vessel show...   \n",
       "7   What are warning signs of a runaway chemical r...   \n",
       "8   What precautions are needed when handling sodi...   \n",
       "9   How do I respond to a leak in a gas storage fa...   \n",
       "10  What should I do if electrical equipment catch...   \n",
       "11  How do I safely manage batch reactor temperatu...   \n",
       "12  What are key considerations for storing flamma...   \n",
       "13  How should I respond to a cooling system failu...   \n",
       "14  What measures prevent dust explosions in proce...   \n",
       "15   How do I handle a leak in pressurized equipment?   \n",
       "16  What safety checks are needed before maintenan...   \n",
       "17  How should I respond to a chemical exposure in...   \n",
       "18      What are signs of imminent equipment failure?   \n",
       "19  How do I safely conduct hot work in hazardous ...   \n",
       "20  What emergency procedures are needed for power...   \n",
       "21      How should I handle a toxic material release?   \n",
       "22  What are proper procedures for chemical waste ...   \n",
       "23  How do I respond to an automatic fire suppress...   \n",
       "\n",
       "                                            Reference  \n",
       "0   Immediately activate fire alarm, evacuate non-...  \n",
       "1   Abnormal pressure readings, unusual temperatur...  \n",
       "2   Likely filamentous bacteria growth caused by: ...  \n",
       "3   Activate emergency alarms, evacuate personnel ...  \n",
       "4   Identify spilled substance from safety data sh...  \n",
       "5   Regular inspection of trapping sieves, tempera...  \n",
       "6   Evacuate area immediately, activate emergency ...  \n",
       "7   Unexpected temperature increase, unusual color...  \n",
       "8   Keep away from moisture and heat above 40°C, a...  \n",
       "9   Activate emergency shutdown systems, evacuate ...  \n",
       "10  Cut power supply if safe, use appropriate fire...  \n",
       "11  Monitor temperature continuously, maintain coo...  \n",
       "12  Proper ventilation, temperature control, segre...  \n",
       "13  Initiate emergency shutdown procedures, activa...  \n",
       "14  Regular cleaning schedule, proper ventilation,...  \n",
       "15  Isolate affected equipment, evacuate area, wea...  \n",
       "16  Verify lockout/tagout, test for hazardous atmo...  \n",
       "17  Remove affected person from exposure, use emer...  \n",
       "18  Unusual noise or vibration, unexpected tempera...  \n",
       "19  Obtain hot work permit, check for flammable at...  \n",
       "20  Activate emergency power systems, secure criti...  \n",
       "21  Activate emergency response plan, evacuate aff...  \n",
       "22  Identify waste type, use proper containers, en...  \n",
       "23  Establish fire watch, notify maintenance, veri...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv(\"../../data/test.csv\")\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8081/v1/schema/Incident \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "memory = ConversationBufferWindowMemory(window_size=3)\n",
    "\n",
    "context = RunnablePassthrough.assign(chat_history= memory.load_variables | itemgetter(\"history\")) | CONTEXT_PROMPT | llm | StrOutputParser()\n",
    "runnable = (\n",
    "            RunnablePassthrough.assign(\n",
    "                memory = memory.load_memory_variables | itemgetter(\"history\"),\n",
    "                industries=\"all\"\n",
    "            )\n",
    "            | retrieve\n",
    "            | SYSTEM_PROMPT \n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "def get_answer_and_context(question):\n",
    "    input = context.invoke({\"question\": question})\n",
    "    answer = runnable.invoke(input)\n",
    "    return input['context'], answer\n",
    "\n",
    "retrieved_contexts = []\n",
    "responses = []\n",
    "\n",
    "for index, row in test_set.iterrows():\n",
    "    time.sleep(60)\n",
    "    input = row[\"Input\"]\n",
    "    context, response = get_answer_and_context(input)\n",
    "    retrieved_contexts.append(context)\n",
    "    responses.append(response)\n",
    "\n",
    "len(retrieved_contexts), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"Retrieved Context\"] = retrieved_contexts\n",
    "test_set[\"Response\"] = responses\n",
    "test_set.to_csv(\"../../data/test_results_ablation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "  def default(self, obj):\n",
    "      if isinstance(obj, datetime):\n",
    "          return obj.isoformat()\n",
    "      return super().default(obj)\n",
    "\n",
    "def convert_context_to_string(context):\n",
    "    context = eval(context)\n",
    "    return list(json.dumps(document, cls=CustomJSONEncoder) for document in context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"../../data/test_results_ablation.csv\")\n",
    "eval_dataset = test_set[[\"Input\", \"Retrieved Context\", \"Response\", \"Reference\"]]\n",
    "eval_dataset = eval_dataset.rename(columns={\"Input\": \"user_input\", \"Retrieved Context\": \"retrieved_contexts\", \"Response\": \"response\", \"Reference\": \"reference\"})\n",
    "eval_dataset[\"retrieved_contexts\"] = eval_dataset[\"retrieved_contexts\"].apply(convert_context_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-large-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.9999999999666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.7142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9785976240736435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 1.0\n",
      "Processing sample 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 6.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9425927765202639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 0.0\n",
      "Processing sample 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.8333333332916666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9981316080911573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 0.6428571428571429\n",
      "Processing sample 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.99999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.2857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9624806137187437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 0.3333333333333333\n",
      "Processing sample 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.9999999999666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9187990877420701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 1.0\n",
      "Processing sample 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.5833333333041666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9630427581001899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 0.23076923076923078\n",
      "Processing sample 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.8333333332916666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9779456706838795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 0.9444444444444444\n",
      "Processing sample 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.49999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9602930033934013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 0.875\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (23) does not match length of index (24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[43meval_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContext Precision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m context_precision\n\u001b[1;32m     53\u001b[0m eval_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext Recall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m context_recall\n\u001b[1;32m     54\u001b[0m eval_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Relevancy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m response_relevancy\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_env/lib/python3.12/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_env/lib/python3.12/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_env/lib/python3.12/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_env/lib/python3.12/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (23) does not match length of index (24)"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference, LLMContextRecall, ResponseRelevancy, Faithfulness\n",
    "from ragas import SingleTurnSample\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import time\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(\n",
    "  openai_api_base=\"https://api.groq.com/openai/v1/\",\n",
    "  model = \"llama3-70b-8192\",\n",
    "  temperature=0.7,\n",
    "  api_key=\"\"\n",
    "))\n",
    "\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\", cache_folder=\"./embedding_model\"))\n",
    "\n",
    "metrics = [\n",
    "  LLMContextPrecisionWithoutReference(llm=evaluator_llm),\n",
    "  LLMContextRecall(llm=evaluator_llm),\n",
    "  ResponseRelevancy(llm=evaluator_llm, embeddings=evaluator_embeddings),\n",
    "  Faithfulness(llm=evaluator_llm)\n",
    "]\n",
    "\n",
    "\n",
    "context_precision = []\n",
    "context_recall = []\n",
    "response_relevancy = []\n",
    "faithfulness = []\n",
    "\n",
    "for index, row in eval_dataset.iterrows():\n",
    "  sample = SingleTurnSample(\n",
    "    user_input=row['user_input'],\n",
    "    response = row[\"response\"],\n",
    "    retrieved_contexts=row[\"retrieved_contexts\"],\n",
    "    reference=row[\"reference\"]\n",
    "  )\n",
    "  print(f\"Processing sample {index + 1}\")\n",
    "  for metric in metrics:\n",
    "    score = metric.single_turn_score(sample)\n",
    "    if metric.name == \"llm_context_precision_without_reference\":\n",
    "      context_precision.append(score)\n",
    "    elif metric.name == \"context_recall\":\n",
    "      context_recall.append(score)\n",
    "    elif metric.name == \"answer_relevancy\":\n",
    "      response_relevancy.append(score)\n",
    "    else:\n",
    "      faithfulness.append(score)\n",
    "    print(f\"{metric.name}: {score}\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_context_precision_without_reference: 0.3333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 15.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relevancy: 0.9631674341449448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 32.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness: 0.3684210526315789\n"
     ]
    }
   ],
   "source": [
    "row = eval_dataset.iloc[15]\n",
    "sample = SingleTurnSample(\n",
    "    user_input=row['user_input'],\n",
    "    response = row[\"response\"],\n",
    "    retrieved_contexts=row[\"retrieved_contexts\"],\n",
    "    reference=row[\"reference\"]\n",
    "  )\n",
    "print(f\"Processing sample {index + 1}\")\n",
    "for metric in metrics:\n",
    "    score = metric.single_turn_score(sample)\n",
    "    if metric.name == \"llm_context_precision_without_reference\":\n",
    "        context_precision.append(score)\n",
    "    elif metric.name == \"context_recall\":\n",
    "        context_recall.append(score)\n",
    "    elif metric.name == \"answer_relevancy\":\n",
    "        response_relevancy.append(score)\n",
    "    else:\n",
    "        faithfulness.append(score)\n",
    "    print(f\"{metric.name}: {score}\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset[\"Context Precision\"] = context_precision\n",
    "eval_dataset[\"Context Recall\"] = context_recall\n",
    "eval_dataset[\"Response Relevancy\"] = response_relevancy\n",
    "eval_dataset[\"Faithfulness\"] = faithfulness\n",
    "eval_dataset.to_csv(\"../../data/eval_results_ablation_part1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Response Relevancy</th>\n",
       "      <th>Faithfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How should I respond to a fire in an industria...</td>\n",
       "      <td>['{\"accident_id\": 370, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, I can offer a g...</td>\n",
       "      <td>Immediately activate fire alarm, evacuate non-...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.967103</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are signs of an imminent explosion risk i...</td>\n",
       "      <td>['{\"accident_id\": 1097, \"event_type\": \"Major A...</td>\n",
       "      <td>Based on the provided context, I can provide a...</td>\n",
       "      <td>Abnormal pressure readings, unusual temperatur...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm seeing sludge overflow in my refinery's bi...</td>\n",
       "      <td>['{\"accident_id\": 1016, \"event_type\": \"Major A...</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>Likely filamentous bacteria growth caused by: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928917</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What immediate actions should be taken if toxi...</td>\n",
       "      <td>['{\"accident_id\": 1335, \"event_type\": \"Near Mi...</td>\n",
       "      <td>Based on the provided context, I can provide a...</td>\n",
       "      <td>Activate emergency alarms, evacuate personnel ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I safely handle a chemical spill in a p...</td>\n",
       "      <td>['{\"accident_id\": 370, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, I can offer a g...</td>\n",
       "      <td>Identify spilled substance from safety data sh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.970008</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What safety measures are essential for oxygen ...</td>\n",
       "      <td>['{\"accident_id\": 1151, \"event_type\": \"Near Mi...</td>\n",
       "      <td>Based on the provided context, the safety meas...</td>\n",
       "      <td>Regular inspection of trapping sieves, tempera...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How should I respond to a pressure vessel show...</td>\n",
       "      <td>['{\"accident_id\": 244, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, it is recommend...</td>\n",
       "      <td>Evacuate area immediately, activate emergency ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.976582</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are warning signs of a runaway chemical r...</td>\n",
       "      <td>['{\"accident_id\": 26, \"event_type\": \"Major Acc...</td>\n",
       "      <td>Based on the provided context, I can provide a...</td>\n",
       "      <td>Unexpected temperature increase, unusual color...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.996268</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What precautions are needed when handling sodi...</td>\n",
       "      <td>['{\"accident_id\": 742, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, it is mentioned...</td>\n",
       "      <td>Keep away from moisture and heat above 40°C, a...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.996238</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I respond to a leak in a gas storage fa...</td>\n",
       "      <td>['{\"accident_id\": 398, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, I found two inc...</td>\n",
       "      <td>Activate emergency shutdown systems, evacuate ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.959356</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What should I do if electrical equipment catch...</td>\n",
       "      <td>['{\"accident_id\": 370, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, I can offer a g...</td>\n",
       "      <td>Cut power supply if safe, use appropriate fire...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.990958</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How do I safely manage batch reactor temperatu...</td>\n",
       "      <td>['{\"accident_id\": 27, \"event_type\": \"Major Acc...</td>\n",
       "      <td>Based on the provided context, I can offer som...</td>\n",
       "      <td>Monitor temperature continuously, maintain coo...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976781</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What are key considerations for storing flamma...</td>\n",
       "      <td>['{\"accident_id\": 11, \"event_type\": \"Major Acc...</td>\n",
       "      <td>Based on the provided context, key considerati...</td>\n",
       "      <td>Proper ventilation, temperature control, segre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.999034</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How should I respond to a cooling system failu...</td>\n",
       "      <td>['{\"accident_id\": 27, \"event_type\": \"Major Acc...</td>\n",
       "      <td>Based on the provided context, I can provide a...</td>\n",
       "      <td>Initiate emergency shutdown procedures, activa...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.980840</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What measures prevent dust explosions in proce...</td>\n",
       "      <td>['{\"accident_id\": 185, \"event_type\": \"Other Ev...</td>\n",
       "      <td>Based on the provided context, it can be infer...</td>\n",
       "      <td>Regular cleaning schedule, proper ventilation,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.987146</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How do I handle a leak in pressurized equipment?</td>\n",
       "      <td>['{\"accident_id\": 991, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, I can offer som...</td>\n",
       "      <td>Isolate affected equipment, evacuate area, wea...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.978598</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What safety checks are needed before maintenan...</td>\n",
       "      <td>['{\"accident_id\": 526, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, it can be infer...</td>\n",
       "      <td>Verify lockout/tagout, test for hazardous atmo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How should I respond to a chemical exposure in...</td>\n",
       "      <td>['{\"accident_id\": 1274, \"event_type\": \"Near Mi...</td>\n",
       "      <td>Based on the provided context, I can offer a g...</td>\n",
       "      <td>Remove affected person from exposure, use emer...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are signs of imminent equipment failure?</td>\n",
       "      <td>['{\"accident_id\": 26, \"event_type\": \"Major Acc...</td>\n",
       "      <td>Based on the provided context, I can provide a...</td>\n",
       "      <td>Unusual noise or vibration, unexpected tempera...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.962481</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How do I safely conduct hot work in hazardous ...</td>\n",
       "      <td>['{\"accident_id\": 632, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, I can provide a...</td>\n",
       "      <td>Obtain hot work permit, check for flammable at...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.918799</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What emergency procedures are needed for power...</td>\n",
       "      <td>['{\"accident_id\": 1122, \"event_type\": \"Near Mi...</td>\n",
       "      <td>Based on the provided context, I can answer yo...</td>\n",
       "      <td>Activate emergency power systems, secure criti...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.963043</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How should I handle a toxic material release?</td>\n",
       "      <td>['{\"accident_id\": 168, \"event_type\": \"Near Mis...</td>\n",
       "      <td>Based on the provided context, I can offer som...</td>\n",
       "      <td>Activate emergency response plan, evacuate aff...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977946</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What are proper procedures for chemical waste ...</td>\n",
       "      <td>['{\"accident_id\": 229, \"event_type\": \"Other Ev...</td>\n",
       "      <td>Based on the provided context, I can provide a...</td>\n",
       "      <td>Identify waste type, use proper containers, en...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960293</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How do I respond to an automatic fire suppress...</td>\n",
       "      <td>['{\"accident_id\": 322, \"event_type\": \"Major Ac...</td>\n",
       "      <td>Based on the provided context, I found two inc...</td>\n",
       "      <td>Establish fire watch, notify maintenance, veri...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963167</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How should I respond to a fire in an industria...   \n",
       "1   What are signs of an imminent explosion risk i...   \n",
       "2   I'm seeing sludge overflow in my refinery's bi...   \n",
       "3   What immediate actions should be taken if toxi...   \n",
       "4   How do I safely handle a chemical spill in a p...   \n",
       "5   What safety measures are essential for oxygen ...   \n",
       "6   How should I respond to a pressure vessel show...   \n",
       "7   What are warning signs of a runaway chemical r...   \n",
       "8   What precautions are needed when handling sodi...   \n",
       "9   How do I respond to a leak in a gas storage fa...   \n",
       "10  What should I do if electrical equipment catch...   \n",
       "11  How do I safely manage batch reactor temperatu...   \n",
       "12  What are key considerations for storing flamma...   \n",
       "13  How should I respond to a cooling system failu...   \n",
       "14  What measures prevent dust explosions in proce...   \n",
       "15   How do I handle a leak in pressurized equipment?   \n",
       "16  What safety checks are needed before maintenan...   \n",
       "17  How should I respond to a chemical exposure in...   \n",
       "18      What are signs of imminent equipment failure?   \n",
       "19  How do I safely conduct hot work in hazardous ...   \n",
       "20  What emergency procedures are needed for power...   \n",
       "21      How should I handle a toxic material release?   \n",
       "22  What are proper procedures for chemical waste ...   \n",
       "23  How do I respond to an automatic fire suppress...   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   ['{\"accident_id\": 370, \"event_type\": \"Major Ac...   \n",
       "1   ['{\"accident_id\": 1097, \"event_type\": \"Major A...   \n",
       "2   ['{\"accident_id\": 1016, \"event_type\": \"Major A...   \n",
       "3   ['{\"accident_id\": 1335, \"event_type\": \"Near Mi...   \n",
       "4   ['{\"accident_id\": 370, \"event_type\": \"Major Ac...   \n",
       "5   ['{\"accident_id\": 1151, \"event_type\": \"Near Mi...   \n",
       "6   ['{\"accident_id\": 244, \"event_type\": \"Major Ac...   \n",
       "7   ['{\"accident_id\": 26, \"event_type\": \"Major Acc...   \n",
       "8   ['{\"accident_id\": 742, \"event_type\": \"Major Ac...   \n",
       "9   ['{\"accident_id\": 398, \"event_type\": \"Major Ac...   \n",
       "10  ['{\"accident_id\": 370, \"event_type\": \"Major Ac...   \n",
       "11  ['{\"accident_id\": 27, \"event_type\": \"Major Acc...   \n",
       "12  ['{\"accident_id\": 11, \"event_type\": \"Major Acc...   \n",
       "13  ['{\"accident_id\": 27, \"event_type\": \"Major Acc...   \n",
       "14  ['{\"accident_id\": 185, \"event_type\": \"Other Ev...   \n",
       "15  ['{\"accident_id\": 991, \"event_type\": \"Major Ac...   \n",
       "16  ['{\"accident_id\": 526, \"event_type\": \"Major Ac...   \n",
       "17  ['{\"accident_id\": 1274, \"event_type\": \"Near Mi...   \n",
       "18  ['{\"accident_id\": 26, \"event_type\": \"Major Acc...   \n",
       "19  ['{\"accident_id\": 632, \"event_type\": \"Major Ac...   \n",
       "20  ['{\"accident_id\": 1122, \"event_type\": \"Near Mi...   \n",
       "21  ['{\"accident_id\": 168, \"event_type\": \"Near Mis...   \n",
       "22  ['{\"accident_id\": 229, \"event_type\": \"Other Ev...   \n",
       "23  ['{\"accident_id\": 322, \"event_type\": \"Major Ac...   \n",
       "\n",
       "                                             response  \\\n",
       "0   Based on the provided context, I can offer a g...   \n",
       "1   Based on the provided context, I can provide a...   \n",
       "2   Based on the provided context, it appears that...   \n",
       "3   Based on the provided context, I can provide a...   \n",
       "4   Based on the provided context, I can offer a g...   \n",
       "5   Based on the provided context, the safety meas...   \n",
       "6   Based on the provided context, it is recommend...   \n",
       "7   Based on the provided context, I can provide a...   \n",
       "8   Based on the provided context, it is mentioned...   \n",
       "9   Based on the provided context, I found two inc...   \n",
       "10  Based on the provided context, I can offer a g...   \n",
       "11  Based on the provided context, I can offer som...   \n",
       "12  Based on the provided context, key considerati...   \n",
       "13  Based on the provided context, I can provide a...   \n",
       "14  Based on the provided context, it can be infer...   \n",
       "15  Based on the provided context, I can offer som...   \n",
       "16  Based on the provided context, it can be infer...   \n",
       "17  Based on the provided context, I can offer a g...   \n",
       "18  Based on the provided context, I can provide a...   \n",
       "19  Based on the provided context, I can provide a...   \n",
       "20  Based on the provided context, I can answer yo...   \n",
       "21  Based on the provided context, I can offer som...   \n",
       "22  Based on the provided context, I can provide a...   \n",
       "23  Based on the provided context, I found two inc...   \n",
       "\n",
       "                                            reference  Context Precision  \\\n",
       "0   Immediately activate fire alarm, evacuate non-...           0.833333   \n",
       "1   Abnormal pressure readings, unusual temperatur...           0.000000   \n",
       "2   Likely filamentous bacteria growth caused by: ...           1.000000   \n",
       "3   Activate emergency alarms, evacuate personnel ...           1.000000   \n",
       "4   Identify spilled substance from safety data sh...           0.000000   \n",
       "5   Regular inspection of trapping sieves, tempera...           1.000000   \n",
       "6   Evacuate area immediately, activate emergency ...           1.000000   \n",
       "7   Unexpected temperature increase, unusual color...           0.000000   \n",
       "8   Keep away from moisture and heat above 40°C, a...           1.000000   \n",
       "9   Activate emergency shutdown systems, evacuate ...           1.000000   \n",
       "10  Cut power supply if safe, use appropriate fire...           0.500000   \n",
       "11  Monitor temperature continuously, maintain coo...           0.833333   \n",
       "12  Proper ventilation, temperature control, segre...           1.000000   \n",
       "13  Initiate emergency shutdown procedures, activa...           0.500000   \n",
       "14  Regular cleaning schedule, proper ventilation,...           1.000000   \n",
       "15  Isolate affected equipment, evacuate area, wea...           1.000000   \n",
       "16  Verify lockout/tagout, test for hazardous atmo...           0.000000   \n",
       "17  Remove affected person from exposure, use emer...           0.833333   \n",
       "18  Unusual noise or vibration, unexpected tempera...           1.000000   \n",
       "19  Obtain hot work permit, check for flammable at...           1.000000   \n",
       "20  Activate emergency power systems, secure criti...           0.583333   \n",
       "21  Activate emergency response plan, evacuate aff...           0.833333   \n",
       "22  Identify waste type, use proper containers, en...           0.500000   \n",
       "23  Establish fire watch, notify maintenance, veri...           0.333333   \n",
       "\n",
       "    Context Recall  Response Relevancy  Faithfulness  \n",
       "0         0.571429            0.967103      0.950000  \n",
       "1         0.500000            0.999128      0.200000  \n",
       "2         1.000000            0.928917      0.571429  \n",
       "3         1.000000            0.996018      1.000000  \n",
       "4         0.375000            0.970008      0.066667  \n",
       "5         0.000000            1.000000      1.000000  \n",
       "6         0.428571            0.976582      1.000000  \n",
       "7         0.500000            0.996268      0.454545  \n",
       "8         0.500000            0.996238      1.000000  \n",
       "9         0.500000            0.959356      0.500000  \n",
       "10        0.625000            0.990958      0.090909  \n",
       "11        0.000000            0.976781      0.461538  \n",
       "12        0.375000            0.999034      1.000000  \n",
       "13        0.428571            0.980840      0.937500  \n",
       "14        0.375000            0.987146      1.000000  \n",
       "15        0.714286            0.978598      1.000000  \n",
       "16        0.000000            0.942593      0.000000  \n",
       "17        1.000000            0.998132      0.642857  \n",
       "18        0.285714            0.962481      0.333333  \n",
       "19        0.833333            0.918799      1.000000  \n",
       "20        0.625000            0.963043      0.230769  \n",
       "21        0.000000            0.977946      0.944444  \n",
       "22        0.000000            0.960293      0.875000  \n",
       "23        0.000000            0.963167      0.368421  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"../../data/eval_results_ablation_part1.csv\")\n",
    "df1.to_csv(\"../../data/eval_results_ablation.csv\", index=False)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Context Precision: 0.6979166666251736\n",
      "Mean Context Recall: 0.44320436507936506\n",
      "Mean Response Relevancy: 0.9745594836726467\n",
      "Mean Faithfulness: 0.6511422270468322\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Context Precision:\", df1[\"Context Precision\"].mean())\n",
    "print(\"Mean Context Recall:\", df1[\"Context Recall\"].mean())\n",
    "print(\"Mean Response Relevancy:\", df1[\"Response Relevancy\"].mean())\n",
    "print(\"Mean Faithfulness:\", df1[\"Faithfulness\"].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
